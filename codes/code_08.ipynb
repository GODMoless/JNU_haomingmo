{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135305e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: pacman\n",
      "\n",
      "Warning message:\n",
      "\"package 'pacman' was built under R version 3.6.3\"\n",
      "\n",
      " Registered number of cores:\n",
      " 8 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "#                                 \n",
    "#             OVERVIEW            \n",
    "#                                 \n",
    "###################################\n",
    "\n",
    "# This code implements a set of base classifiers using original data sets. Processed\n",
    "# and partitioned data are imported from the files saved in `code_00_partitioning.ipynb`. \n",
    "# The code saves intermediate results in `results`.\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "#                                 \n",
    "#             SETTINGS            \n",
    "#                                 \n",
    "###################################\n",
    "\n",
    "# clearing the memory\n",
    "rm(list = ls())\n",
    "\n",
    "# installing pacman\n",
    "if (require(pacman) == F) install.packages('pacman')\n",
    "library(pacman)\n",
    "\n",
    "# libraries\n",
    "p_load(caret, doParallel, kernlab, randomForest, nnet, \n",
    "       xgboost, foreach, e1071, pROC, EMP)\n",
    "\n",
    "# working directory\n",
    "cd <- 'C:/Users/PC/Fair_Credit_Scoring-main/codes'\n",
    "setwd(dirname(cd))\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "#                                 \n",
    "#           PARAMETERS            \n",
    "#                                 \n",
    "###################################\n",
    "\n",
    "# paths\n",
    "source(file.path(cd, 'code_00_working_paths.R'))\n",
    "\n",
    "# data \n",
    "data <- 'taiwan'\n",
    "\n",
    "# partitioning\n",
    "num_folds <- 5\n",
    "seed      <- 1\n",
    "\n",
    "# cores\n",
    "cores <- 8\n",
    "\n",
    "# options\n",
    "set.seed(seed)\n",
    "options(scipen = 10)\n",
    "\n",
    "# parallel computing\n",
    "nrOfCores <- cores\n",
    "registerDoParallel(cores = nrOfCores)\n",
    "message(paste('\\n Registered number of cores:\\n',nrOfCores,'\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97dff616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"----------------------------------------\"\n",
      "[1] \"FOLD: 0\"\n",
      "[1] \"----------------------------------------\"\n",
      "[1] \"-- glm...\"\n",
      "Aggregating results\n",
      "Fitting final model on full training set\n",
      "[1] \"-- model glm finished training: 2023-04-03 15:55:28\"\n",
      "[1] \"-- rf...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting mtry = 5 on full training set\n",
      "[1] \"-- model rf finished training: 2023-04-03 15:58:02\"\n",
      "[1] \"-- xgbTree...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting nrounds = 100, max_depth = 5, eta = 0.1, gamma = 0, colsample_bytree = 0.5, min_child_weight = 0.5, subsample = 1 on full training set\n",
      "[1] \"-- model xgbTree finished training: 2023-04-03 16:17:24\"\n",
      "[1] \"-- nnet...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting size = 5, decay = 2 on full training set\n",
      "[1] \"-- model nnet finished training: 2023-04-03 16:18:27\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"----------------------------------------\"\n",
      "[1] \"FOLD: 1\"\n",
      "[1] \"----------------------------------------\"\n",
      "[1] \"-- glm...\"\n",
      "Aggregating results\n",
      "Fitting final model on full training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"glm.fit: algorithm did not converge\"\n",
      "Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"-- model glm finished training: 2023-04-03 16:18:51\"\n",
      "[1] \"-- rf...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting mtry = 10 on full training set\n",
      "[1] \"-- model rf finished training: 2023-04-03 16:23:17\"\n",
      "[1] \"-- xgbTree...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting nrounds = 100, max_depth = 5, eta = 0.1, gamma = 0, colsample_bytree = 0.5, min_child_weight = 0.5, subsample = 0.5 on full training set\n",
      "[1] \"-- model xgbTree finished training: 2023-04-03 16:47:57\"\n",
      "[1] \"-- nnet...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting size = 5, decay = 1 on full training set\n",
      "[1] \"-- model nnet finished training: 2023-04-03 16:49:06\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"----------------------------------------\"\n",
      "[1] \"FOLD: 2\"\n",
      "[1] \"----------------------------------------\"\n",
      "[1] \"-- glm...\"\n",
      "Aggregating results\n",
      "Fitting final model on full training set\n",
      "[1] \"-- model glm finished training: 2023-04-03 16:49:29\"\n",
      "[1] \"-- rf...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting mtry = 5 on full training set\n",
      "[1] \"-- model rf finished training: 2023-04-03 16:53:38\"\n",
      "[1] \"-- xgbTree...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting nrounds = 100, max_depth = 10, eta = 0.1, gamma = 0, colsample_bytree = 0.5, min_child_weight = 3, subsample = 1 on full training set\n",
      "[1] \"-- model xgbTree finished training: 2023-04-03 17:18:21\"\n",
      "[1] \"-- nnet...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting size = 5, decay = 2 on full training set\n",
      "[1] \"-- model nnet finished training: 2023-04-03 17:19:23\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"----------------------------------------\"\n",
      "[1] \"FOLD: 3\"\n",
      "[1] \"----------------------------------------\"\n",
      "[1] \"-- glm...\"\n",
      "Aggregating results\n",
      "Fitting final model on full training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"glm.fit: algorithm did not converge\"\n",
      "Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"-- model glm finished training: 2023-04-03 17:19:41\"\n",
      "[1] \"-- rf...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting mtry = 5 on full training set\n",
      "[1] \"-- model rf finished training: 2023-04-03 17:22:13\"\n",
      "[1] \"-- xgbTree...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting nrounds = 100, max_depth = 5, eta = 0.1, gamma = 0, colsample_bytree = 0.5, min_child_weight = 1, subsample = 1 on full training set\n",
      "[1] \"-- model xgbTree finished training: 2023-04-03 17:39:34\"\n",
      "[1] \"-- nnet...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting size = 5, decay = 2 on full training set\n",
      "[1] \"-- model nnet finished training: 2023-04-03 17:40:24\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"----------------------------------------\"\n",
      "[1] \"FOLD: 4\"\n",
      "[1] \"----------------------------------------\"\n",
      "[1] \"-- glm...\"\n",
      "Aggregating results\n",
      "Fitting final model on full training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"glm.fit: algorithm did not converge\"\n",
      "Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"-- model glm finished training: 2023-04-03 17:40:41\"\n",
      "[1] \"-- rf...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting mtry = 5 on full training set\n",
      "[1] \"-- model rf finished training: 2023-04-03 17:43:18\"\n",
      "[1] \"-- xgbTree...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting nrounds = 100, max_depth = 5, eta = 0.1, gamma = 0, colsample_bytree = 0.5, min_child_weight = 0.5, subsample = 1 on full training set\n",
      "[1] \"-- model xgbTree finished training: 2023-04-03 18:00:47\"\n",
      "[1] \"-- nnet...\"\n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting size = 5, decay = 1.5 on full training set\n",
      "[1] \"-- model nnet finished training: 2023-04-03 18:01:40\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n",
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\"\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "#                                \n",
    "#          MODELING      \n",
    "#                                \n",
    "##################################\n",
    "\n",
    "# helper functions\n",
    "source(file.path(func_path, '95_fairness_metrics.R'))\n",
    "source(file.path(func_path, '96_emp_summary.R'))\n",
    "\n",
    "# modeling\n",
    "for (fold in seq(0, num_folds - 1)) {\n",
    "  \n",
    "  \n",
    "  #---- PREPARATIONS ----\n",
    "  \n",
    "  # feedback\n",
    "  print('----------------------------------------')\n",
    "  print(paste0('FOLD: ', fold))\n",
    "  print('----------------------------------------')\n",
    "\n",
    "  # read data\n",
    "  dtest  <- read.csv(file.path(data_path, 'prepared', paste0(data, '_scaled_', fold, '_test.csv')))\n",
    "  dval   <- read.csv(file.path(data_path, 'prepared', paste0(data, '_scaled_', fold, '_valid.csv')))\n",
    "  dtrain <- read.csv(file.path(data_path, 'prepared', paste0(data, '_scaled_', fold, '_train.csv')))\n",
    "  \n",
    "  # factor encoding\n",
    "  dtrain$TARGET <- as.factor(ifelse(dtrain$TARGET == 1, 'Good', 'Bad'))\n",
    "  dval$TARGET   <- as.factor(ifelse(dval$TARGET   == 1, 'Good', 'Bad'))\n",
    "  dtest$TARGET  <- as.factor(ifelse(dtest$TARGET  == 1, 'Good', 'Bad'))\n",
    "  dtrain$AGE    <- as.factor(ifelse(dtrain$AGE == 1,    'Old',  'Young'))\n",
    "  dval$AGE      <- as.factor(ifelse(dval$AGE   == 1,    'Old',  'Young'))\n",
    "  dtest$AGE     <- as.factor(ifelse(dtest$AGE  == 1,    'Old',  'Young'))\n",
    "\n",
    "  \n",
    "  #---- TRAINING ----\n",
    "  \n",
    "  # grid search params\n",
    "  source(file.path(func_path, '97_caret_settings.R'))\n",
    "  source(file.path(func_path, '98_param_grids.R'))\n",
    "\n",
    "  # train models and save result to model.'name'\n",
    "  for (m in model.names) {\n",
    "    print(paste0('-- ', m, '...'))\n",
    "    grid <- get(paste('param.', m, sep = ''))\n",
    "    args.train <- list(TARGET~., \n",
    "                       data      = dtrain,  \n",
    "                       method    = m, \n",
    "                       tuneGrid  = grid,\n",
    "                       metric    = 'EMP',\n",
    "                       trControl = model.control)\n",
    "    args.model <- c(args.train, get(paste('args.', m, sep = '')))\n",
    "    assign(paste('model.', m, sep = ''), do.call(train, args.model))\n",
    "    print(paste('-- model', m, 'finished training:', Sys.time(), sep = ' '))\n",
    "  }\n",
    "  \n",
    "  # clean up\n",
    "  for (m in model.names) {\n",
    "    rm(list = c(paste0('args.', m), paste0('param.', m)))\n",
    "  }\n",
    "  gc()\n",
    "  rm(args.model, args.train, model.control)\n",
    "  \n",
    "  \n",
    "  #---- THRESHOLDING ----\n",
    "  \n",
    "  # Find optimal cutoff based on validation set\n",
    "  for (m in model.names) {\n",
    "    pred <- predict(get(paste('model.', m, sep = '')), newdata = dval, type = 'prob')$Good\n",
    "    EMP  <- empCreditScoring(scores = pred, classes = dval$TARGET)\n",
    "    assign(paste0('cutoff.', m), EMP$EMPCfrac)\n",
    "  }\n",
    "  \n",
    "  \n",
    "  #---- TRAINING RESULTS ----\n",
    "  \n",
    "  # save image\n",
    "  save.image(file.path(res_path, 'intermediate', paste0('IMAGE_POST_', data, '_', fold, '.Rdata')))\n",
    "\n",
    "  # loop through data subsets\n",
    "  data.names <- c('dval', 'dtest')\n",
    "  for (data.set in data.names) {\n",
    "    \n",
    "    # placeholders\n",
    "    model_prediction <- NULL\n",
    "    cnames           <- NULL\n",
    "    \n",
    "    # loop through models\n",
    "    for (m in model.names) {\n",
    "\n",
    "      # produce predictions\n",
    "      pred         <- predict(get(paste0('model.', m)), newdata = get(data.set), type = 'prob')$Good\n",
    "      cutoff       <- quantile(pred, get(paste0('cutoff.', m)))\n",
    "      cutoff_label <- sapply(pred, function(x) ifelse(x > cutoff, 'Good', 'Bad'))\n",
    "\n",
    "      # save predictions      \n",
    "      model_prediction <- cbind(model_prediction, pred, cutoff_label)\n",
    "      cnames <- c(cnames, c(paste0(m, '_scores'), paste0(m, '_class')))\n",
    "    }\n",
    "    \n",
    "    # export results\n",
    "    colnames(model_prediction) <- cnames\n",
    "    write.csv(model_prediction, file.path(res_path, 'intermediate', paste0(data, '_', fold, '_POST_training_results_', data.set, '.csv')), row.names = F)\n",
    "  }\n",
    "}\n",
    "\n",
    "# close cluster\n",
    "stopImplicitCluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74a1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
